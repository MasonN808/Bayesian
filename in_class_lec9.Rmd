```{r}
#gamma = log(pi/(1-pi)) : using the prior dist an post dist of pi
# PRIOR
a=1
b=1
n=100000
pi.prior.mc=rbeta(n,a,b)
mean(log(pi.prior.mc/(1-pi.prior.mc)))
```

```{r}
# POSTERIOR
a.p=442
b.p=420
n.p=100000
pi.post.mc=rbeta(n.p,a.p,b.p)
mean(log(pi.post.mc/(1-pi.post.mc)))
```


```{r}
##############Example 1
r=68; v=45;
#mean =r/v=68/45
68/45
#var=r/v^2=68/45^2
#E(X^2)=E(X)^2+Var(X) =(68/45)^2+68/45^2
(68/45)^2+68/45^2

n=100000
x=rgamma(n,r,v)
mean(x)

mean(x^2)
```

```{r}
#Plot the pictures
par(mar=c(3,3,.25,1),mgp=c(1.75,.75,0))
par(mfrow=c(2,3))
set.seed(1)
a<-68 ; b<-45
set.seed(1)
theta.support<-seq(0,3,length=100)
theta.sim10<-rgamma(10,a,b)
theta.sim100<-rgamma(100,a,b)
theta.sim1000<-rgamma(1000,a,b)

xlim<-c(.75,2.25)
ylim=c(0,2.5)
lty=1

hist( theta.sim10, prob=T,xlim=xlim,ylim=ylim,xlab="",main="",ylab="")
lines(theta.support,dgamma(theta.support,a,b),col="gray",lwd=2,lty=lty)
text(2.1,2.25,expression(paste(italic(S),"=10",sep="")))

hist( theta.sim100, prob=T,xlim=xlim,ylim=ylim,xlab="",main="" ,ylab="")
lines(theta.support,dgamma(theta.support,a,b),col="gray",lwd=2,lty=lty)
text(2.1,2.25,expression(paste(italic(S),"=100",sep="")))



hist( theta.sim1000, prob=T,xlim=xlim,ylim=ylim,xlab="",main="" ,ylab="")
lines(theta.support,dgamma(theta.support,a,b),col="gray",lwd=2,lty=lty)
text(2.1,2.25,expression(paste(italic(S),"=1000",sep="")))


plot(density(theta.sim10),xlim=xlim,ylim=ylim,xlab=expression(theta),main="",ylab="")
lines(theta.support,dgamma(theta.support,a,b),col="gray",lwd=2,lty=lty)

plot(density(theta.sim100),xlim=xlim,ylim=ylim,xlab=expression(theta),main="",ylab="")
lines(theta.support,dgamma(theta.support,a,b),col="gray",lwd=2,lty=lty)

plot(density(theta.sim1000),xlim=xlim,ylim=ylim,xlab=expression(theta),main="",ylab="")
lines(theta.support,dgamma(theta.support,a,b),col="gray",lwd=2,lty=lty)
```






#############Example 2



load(url("https://foxweb.marist.edu/users/duy.nguyen2/gss.RData"))
head(gss)
y2<-gss$CHILDS[gss$FEMALE==1 &  gss$YEAR>=1990  & gss$AGE==40 & gss$DEG>=3 ]
y1<-gss$CHILDS[gss$FEMALE==1 &  gss$YEAR>=1990  & gss$AGE==40 & gss$DEG<3 ]

y2<-y2[!is.na(y2)]
y1<-y1[!is.na(y1)]
table(y1)
table(y2)

#pdf("fig.pdf",family="Times",height=3.5,width=7)
par(mar=c(3,3,1,1),mgp=c(1.75,.75,0))
par(mfrow=c(1,2))

set.seed(1) 
n1<-length(y1) ; n2<-length(y2)
s1<-sum(y1)
s2<-sum(y2)

par(mfrow=c(1,2),mar=c(3,3,1,1),mgp=c(1.75,.75,0))
plot(table(y1), type="h",xlab=expression(italic(y)),ylab=expression(italic(n[1](y))),col=gray(.5) ,lwd=3)
mtext("Less than bachelor's",side=3)
plot(table(y2), type="h",xlab=expression(italic(y)),ylab=expression(italic(n[2](y))),col=gray(0),lwd=3)
mtext("Bachelor's or higher",side=3,lwd=3)
#dev.off()


#####posterior distributions

 a=2 ; b=1 # p r i o r parameter s
 n1=111 ; sy1=217 # data in group 1
 n2=44 ; sy2=66 # data in group 2

 #Group 1:
( a+sy1 ) / ( b+n1 ) # p o s t e r i o r mean for group 1
( a+sy1 -1)/(b+n1 ) # p o s t e r i o r mode for group 1
 qgamma( c ( .025 , .975) , a+sy1 , b+n1 ) # p o s t e r i o r 95% CI

 #Group 2:
( a+sy2 ) / ( b+n2 ) #mean
( a+sy2 -1)/(b+n2 ) #mode
qgamma( c ( .025 , .975 ) , a+sy2 , b+n2 ) # p o s t e r i o r 95% CI


#Monte Carlo simulation

#a P(mu2<1.75)

  #exact 
  pgamma(1.75,a+sy2 , b+n2)
  #Monte Calor
  a=2 ; b=1
  sy2=66 ; n2=44
  #approx the prob using 10 sample points
  theta2.mc10=rgamma (10 , a+sy2 , b+n2)
  mean(theta2.mc10<1.75)
  
  #approx the prob using 100 sample points
  theta2.mc100=rgamma(100 , a+sy2 , b+n2)
  mean(theta2.mc100<1.75)
  
  #approx the prob using 1000 sample points
  theta2.mc1000=rgamma(1000 , a+sy2 , b+n2)
  mean(theta2.mc1000<1.75)
  
  #plot
  x=c(10,100,1000)
  yexact=rep(pgamma(1.75,a+sy2 , b+n2),3)
  
  plot(x,yexact,col="red",type="l",ylab="",xlab="Number of points")
  lines(x,c(mean(theta2.mc10<1.75),mean(theta2.mc100<1.75),mean(theta2.mc1000<1.75)),lty=3)


#c) P(mu1>mu2)
 a=2 ; b=1
 sy1=217 ; n1=111
 sy2=66 ; n2=44
 #approx the prob using 10000 sample points
 theta1.mc=rgamma(10000 , a+sy1 , b+n1 )
 theta2.mc=rgamma(10000 , a+sy2 , b+n2 )
 mean(theta1.mc>theta2.mc)
 
 
```{r}
 #Example 3: 
 
 
 a=1; b=1
 #prior estimate of gamma
 pi.prior.mc=rbeta (10000 , a , b)
 gamma.prior.mc=log(pi.prior.mc/(1-pi.prior.mc) )
 mean(gamma.prior.mc)
 
 #post estimate of gamma
 n0=860-441 ; n1=441
 pi.post.mc=rbeta (10000 , a+n1 , b+n0 )
 gamma.post.mc=log( pi.post.mc/(1-pi.post.mc) )
 mean(gamma.post.mc)
```
 
 
```{r}
 par(mar=c(3,3,1,1),mgp=c(1.75,.75,0))
 par(mfrow=c(2,3))
 par(cex=.8)
 
 par(mfrow=c(1,2),mar=c(3,3,1,1), mgp=c(1.75,.75,.0))
 plot(density(gamma.prior.mc,adj=2),xlim=c(-5,5),main="", 
      xlab=expression(gamma),
      ylab=expression(italic(p(gamma))),col="gray")
 plot(density(gamma.post.mc,adj=2),xlim=c(-5,5),main="",xlab=expression(gamma),
      ylab=expression(paste(italic("p("),gamma,"|",y[1],"...",y[n],")",
                            sep="")) )
 lines(density(gamma.prior.mc,adj=2),col="gray")
```
 
 
 
```{r}
 ######Midge wing length : conjugate case
 
 
 ##### prior and posterior calculations
 
 ## prior
 mu0<-1.9  ; k0<-1 # k0 in the note
 s20<-.01 ; nu0<-1 # v0 in the note
 
 ## data
 y<-c(1.64,1.70,1.72,1.74,1.82,1.82,1.82,1.90,2.08)
 n<-length(y) ; ybar<-mean(y) ; s2<-var(y)
 
 ## posterior inference
 kn<-k0+n ; nun<-nu0+n
 mun<- (k0*mu0 + n*ybar)/kn  
 s2n<- (nu0*s20 +(n-1)*s2 +k0*n*(ybar-mu0)^2/(kn))/(nun)
 mun
 s2n
```

```{r}
 dinvgamma<-function(x,a,b) {
   ld<- a*log(b) -lgamma(a) -(a+1)*log(x)  -b/x 
   exp(ld)
 }
 
 gs<-100 # The N in the note
 theta<-seq(1.6,2.0,length=gs) # Theta = mu in the note; 1.6 = L1, 2.0 = L2
 is2<-seq(15,160 ,length=gs)  # tilda(sigma^2)=1/sigma^2
 s2g<-seq(.001,.045,length=gs)
 
 ld.th.is2<-ld.th.s2<-matrix(0,gs,gs) # make matrix to save the values to calculate the joint dist
 for(i in 1:gs) { for(j in 1:gs) {
   ld.th.is2[i,j]<- dnorm(theta[i],mun,1/sqrt( is2[j] *10) ,log=TRUE) +
     dgamma(is2[j],10/2,10*s2n/2, log=TRUE )
   ld.th.s2[i,j]<- dnorm(theta[i],mun,sqrt(s2g[j]/10) ,log=TRUE) +
     log(dinvgamma(s2g[j],10/2,10*s2n/2 ))
 }} 
 
 par(mfrow=c(1,2),mar=c(3,3,1,1),mgp=c(1.75,.75,0))
 grays<- gray( (10:0)/10)
 image(theta,is2,exp(ld.th.is2),col=grays,xlab=expression(theta),
       ylab=expression(tilde(sigma)^2) ) 
 image(theta,s2g,exp(ld.th.s2), col=grays,xlab=expression(theta),
       ylab=expression(sigma^2) )
```
```{r}
data = matrix(0,10,10)
x = seq(-1,1,.2)
y = seq(-1,1,.2)
for (i in x){
  for (j in y) {
    data[i,j] <- i^2 + j^2
  }
}
# par(mfrow=c(1),mar=c(3,3,1,1),mgp=c(1.75,.75,0))
# grays<- gray((10:0)/10)
image(x,y,data,xlab=expression(x),
       ylab=expression(y) ) 
```
#10/9 Class
```{r}
dinvgamma <- function(x,a,b) {
  # return hte density at x for gamma(a,b)
  ld = a*log(b)-lgamma(a)-(a+1)*log(x)-b/x
  exp(ld)
}

N=100
mu = seq(1.6,2,length=N)
s2g=seq(.001, .045, length=N)

jointpdf=matrix(0,N,N)
for(i in 1:N) {
  for (j in 1:N) {
    jointpdf[i,j]=dnorm(mu[i], mean=1.814, sd=sqrt(s2g[j]/10))*dinvgamma(s2g[j],10/2,10*.015/2)
  }
}

image(mu,s2g, jointpdf)

```
```{r}
# In-class Midge example
y <- c(1.64,1.70,1.72,1.74,1.82,1.82,1.82,1.90,2.08)
n <- length(y); mean.y <- mean(y) ; var.y <- var(y)

# priors
# mu ~ N(mu0, tau0^2)
mu0=1.9; t20=.95^2

# sigma^2 ~ inversgamma(v0, v0sigma0^2/2)
# sigmatilde^2=1/sigma^2 ~ gamma(v0, v0sigma0^2/2)

v0=1; s20=.01

G=100
H=100

jointpdf=matrix(0,G,H)
# sigt = sigma tilde
sigt=seq(1.75, 175, length=H)


# joint dist
for (i in 1:G) {
  for (j in 1:H) {
    # Normal * Gamma * likelihood
    jointpdf[i,j] = dnorm(mu[i], mean=mu0, sd=sqrt(t20))*dgamma(sigt[j], v0/2, v0*s20/2)*
                    prod(dnorm(y, mean=mu[i], sd=1/sqrt(sigt[j])))
  }
}

# post joint dist
post.jointpdf = jointpdf/sum(jointpdf)

image(mu,sigt,post.jointpdf)

# post pdf for mu
# summing by rows
post.pdfmu=apply(post.jointpdf,1,sum)
plot(mu,post.pdfmu)
mean(post.pdfmu)

# post pdf of sigmatidle = 1/sigma^2
# summing by columns
post.pdfsigt=apply(post.jointpdf,2,sum)
plot(sigt, post.pdfsigt)

# post pdf for sigma^2
plot(1/sigt, 1/post.pdfsigt)

```








```{r}
 #Midge example: semiconjucate case from r codes in ilearn
 
 
 # priors
 mu0<-1.9  ; t20<-0.95^2
 s20<-.01 ; nu0<-1
 
 # data
 y<-c(1.64,1.70,1.72,1.74,1.82,1.82,1.82,1.90,2.08)
 n<-length(y) ; mean.y<-mean(y) ; var.y<-var(y)
 
 
 # grid 
 G<-100 ; H<-100
 
 mean.grid<-seq(1.505,2.00,length=G) 
 prec.grid<-seq(1.75,175,length=H) 
 
 post.grid<-matrix(nrow=G,ncol=H)
 
 for(g in 1:G) {
   for(h in 1:H) { 
     
     post.grid[g,h]<- dnorm(mean.grid[g], mu0, sqrt(t20)) *
       dgamma(prec.grid[h], nu0/2, s20*nu0/2 ) *
       prod( dnorm(y,mean.grid[g],1/sqrt(prec.grid[h])) )
   }
 }
 
 post.grid<-post.grid/sum(post.grid)
 
 
 par(mfrow=c(1,3),mar=c(2.75,2.75,.5,.5),mgp=c(1.70,.70,0))
 image( mean.grid,prec.grid,post.grid,col=gray( (10:0)/10 ),
        xlab=expression(theta), ylab=expression(tilde(sigma)^2) )
 
 mean.post<- apply(post.grid,1,sum)
 plot(mean.grid,mean.post,type="l",xlab=expression(theta),
      ylab=expression( paste(italic("p("),
                             theta,"|",italic(y[1]),"...",italic(y[n]),")",sep="")))
 
 prec.post<-apply(post.grid,2,sum)
 plot(prec.grid,prec.post,type="l",xlab=expression(tilde(sigma)^2),
      ylab=expression( paste(italic("p("),
                             tilde(sigma)^2,"|",italic(y[1]),"...",italic(y[n]),")",sep=""))) 
 
```

 
 
